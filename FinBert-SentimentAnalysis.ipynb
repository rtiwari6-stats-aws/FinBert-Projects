{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18d8327a-9b8c-47c2-856a-8e220146cace",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.40.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2024.4.16)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed5ef0e9-b626-4430-9db8-41bb7087576d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "763ee513-d98e-4cf6-ba3b-197a7e2f79c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                               Text\n",
       "0   neutral  According to Gran , the company has no plans t...\n",
       "1   neutral  Technopolis plans to develop in stages an area...\n",
       "2  negative  The international electronic industry company ...\n",
       "3  positive  With the new production plant the company woul...\n",
       "4  positive  According to the company 's updated strategy f..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('all-data.csv', \n",
    "                   encoding='unicode_escape',\n",
    "                   names=['Sentiment', 'Text'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20d60d3b-60e0-480e-b988-4eab35e7a8ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive': 0.45130324, 'negative': 0.09192983, 'neutral': 0.4567669}\n",
      "Predicted sentiment for 'The company's stock price is not expected to surge in the coming months.': neutral\n",
      "{'positive': 0.008231973, 'negative': 0.94887114, 'neutral': 0.04289689}\n",
      "Predicted sentiment for 'The company's stock price is going down.': negative\n",
      "{'positive': 0.43633714, 'negative': 0.5117515, 'neutral': 0.05191137}\n",
      "Predicted sentiment for 'The british pound weakened but stocks rallied.': negative\n"
     ]
    }
   ],
   "source": [
    "# Load the FinBERT model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "tokenizer_kwargs = {\"padding\": True, \"truncation\": True, \"max_length\": 512}\n",
    "\n",
    "# Define a function to predict sentiment\n",
    "def predict_sentiment(text):\n",
    "    encoded_text = tokenizer(text, return_tensors=\"pt\", **tokenizer_kwargs)\n",
    "    # Get predictions from the model\n",
    "    with torch.no_grad():\n",
    "        logits = model(**encoded_text).logits\n",
    "    scores = {k: v for k, v in zip(model.config.id2label.values(), scipy.special.softmax(logits.numpy().squeeze()))}\n",
    "    print(scores)\n",
    "    print(f\"Predicted sentiment for '{text}': {max(scores, key=scores.get)}\")\n",
    "\n",
    "\n",
    "test_text = \"The company's stock price is not expected to surge in the coming months.\"\n",
    "predict_sentiment(test_text)\n",
    "\n",
    "\n",
    "test_text = \"The company's stock price is going down.\"\n",
    "predict_sentiment(test_text)\n",
    "\n",
    "test_text = \"The british pound weakened but stocks rallied.\"\n",
    "predict_sentiment(test_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cc65df4-645f-4da6-b925-616e08332f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "preds_proba = []\n",
    "text=data['Text'].tolist()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "tokenizer_kwargs = {\"padding\": True, \"truncation\": True, \"max_length\": 512}\n",
    "for x in text:\n",
    "    # disable gradient calculation for efficiency since we're not performing backpropagation during prediction.\n",
    "    with torch.no_grad():\n",
    "        # This line uses the tokenizer to convert the current text x into a format suitable for the model. \n",
    "        # The return_tensors=\"pt\" argument specifies converting the data to PyTorch tensors, \n",
    "        # and the **tokenizer_kwargs dictionary unpacks additional arguments like \n",
    "        # padding, truncation, and maximum sequence length (set to 512 here).\n",
    "        input_sequence = tokenizer(x, return_tensors=\"pt\", **tokenizer_kwargs)\n",
    "        # These logits represent the raw scores for each possible sentiment class.\n",
    "        logits = model(**input_sequence).logits\n",
    "        # create a dictionary to store the predicted sentiment label and its corresponding probability score\n",
    "        scores = {\n",
    "        k: v\n",
    "        # iterates through the model's configuration (model.config.id2label.values()) to get the sentiment labels and \n",
    "        # combines them with the softmax probabilities calculated using scipy.special.softmax on the logits \n",
    "        # converted to NumPy array and squeezed to remove extra dimensions\n",
    "        for k, v in zip(\n",
    "            model.config.id2label.values(),\n",
    "            scipy.special.softmax(logits.numpy().squeeze()),\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # This line finds the sentiment label (key) in the scores dictionary with the highest probability value.\n",
    "    sentimentFinbert = max(scores, key=scores.get)\n",
    "    \n",
    "    # This captures the highest probability score (value) from the scores dictionary.\n",
    "    probabilityFinbert = max(scores.values())\n",
    "    preds.append(sentimentFinbert)\n",
    "    preds_proba.append(probabilityFinbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a316ea6-e462-474f-9f66-c47f332927a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy-Score: 0.8893933140734627\n"
     ]
    }
   ],
   "source": [
    "y = data['Sentiment'].to_list()\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "print(f'Accuracy-Score: {accuracy_score(y, preds)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbed36a3-b9e5-4be9-92d9-cdea2d8d97a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
